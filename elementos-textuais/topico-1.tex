\chapter{Introdução}\label{chp:LABEL_CHP_1}

\emph{Support vector machine}, ou máquina de vetores suporte (MVS), é um método de aprendizado de máquina em que, a partir de um conjunto de dados definidos como exemplos, são definidos hiperplanos que separam as classes. Cada exemplo é composto por atributos e uma classe. Atributos são variáveis cujos valores podem ser usados para fazer a predição da classe. Um exemplo onde se desconhece a classe é chamado de caso teste. A máquina de vetores suporte representa os casos teste como pontos em um espaço $n$ dimensional, onde $n$ é o número de atributos do caso teste. A MVS cria um hiperplano que divide esse espaço de forma que seja possível identificar a qual classe o exemplo pertence.
Esse hiperplano é construído a partir da fronteira entre o subespaço ocupado por cada classe. Os pontos que definem essas fronteiras são chamados de vetores suporte.

Neste trabalho, implementamos um algoritmo de MVS que encontra esse hiperplano, avaliando todos os casos teste do conjunto de treinamento e convergindo em direção ao hiperplano que melhor divide o espaço entre os pontos de cada classe. Esse algoritmo é muito custoso computacionalmente, pois é preciso comparar todos os pares de exemplos do conjunto de treinamento a cada iteração.
Desse modo, como temos um conjunto de dados grande e um algoritmo custoso e repetitivo, temos um caso forte para a paralelização.


\par
%silvana: Existem diferentes ambientes para programação paralela, entre eles as GPUs têm ganhado destaque nos último anos...
%Para paralelização escolhi a GPU. 
Existem diferentes ambientes para programação paralela, entre os quais as GPUs (\emph{Graphics Processing Units}) têm ganhado destaque nos último anos. As GPUs tradicionalmente são usadas para computação gráfica e foram otimizadas para processar imagens e espaços com um conjunto enorme de pontos. Entretanto, essa capacidade de processar uma grande quantidade de dados em paralelo tem utilidade em muitos outros campos além dá computação gráfica, onde é necessário um alto nível de paralelismo de dados, como é o caso da MVS.
%silvana: acrescentar dizendo que tipos de problemas se adequam para implementação em GPU (forte paralelismo de dados, como é o caso de MVS...) 
%Felipe: melhor?

\par
A implementação de um MVS usando GPU não é novidade. Catanzaro, Sundaram e Keutzer em 2008 \cite{art:REF_ART_1} mostraram que uma MVS utilizando a arquitetura paralela da GPU poderia ser muito mais rápida. Eles compararam seu desempenho com o LIBSVM \cite{art:LIBSVM}, uma das bibliotecas mais populares e mais completas de MVS, o ganho foi de 9 a 35 vezes melhor no treinamento e de 81 a 138 vezes melhor na classificação. Catanzaro et al. usou o algoritmo SMO, \emph{Sequential Minimal Optimization}, que divide o problema de otimização em problemas menores.
\par
Austin Carpenter em 2009 \cite{art:REF_ART_2} criticou a versão de Catanzaro por não implementar a regressão e obter precisão um pouco abaixo do LIBSVM em um dos conjuntos de dados por usar o tipo float ao invés do tipo double. As GPUs possuem mais unidades lógicas de float do que double, o que motivou a escolha de Catanzaro por velocidade sobre precisão. O programa de Carpenter implementa regressão e usa uma mistura de float e double, recuperando a precisão perdida sem perda de velocidade.
\par
Athanasopoulos et al em 2011\cite{art:REF_ART_3} expandiram a LIBSVM de forma que todas as opções da biblioteca continuam disponíveis e com a mesma precisão, mas com uma velocidade aumentada graças a paralelizações feitas usando GPU.\par


\section{Objetivo do Trabalho}\label{sec:LABEL_CHP_1_SEC_B}
O objetivo deste trabalho é desenvolver uma implementação paralela para GPU de uma máquina de vetores suporte usando o algoritmo Kernel-Adatron descrito por Colin Campbell e Nello Cristianini \cite{art:LIVRO_KAA}. Esse algoritmo é mais simples que o SMO implementado pelos artigos referenciados anteriormente, e normalmente  recomendado como uma introdução à implementação da máquina de vetores suporte.
Além de sua simplicidade, o algoritmo Kernel-Adatron é um forte candidato à implementação paralela por adotar um método repetitivo que requer um elevado esforço de processamento. %ele teria um alto potencial para mostrar melhora em uma versão paralela.
\par
Para avaliar a implementação proposta, usaremos os mesmos conjuntos de dados usados por Catanzaro e Carpenter em seus artigos. Esses conjuntos de dados podem ser encontrados no site do LIBSVM \cite{art:LIBSVM}. 

As métricas de avaliação serão o ganho de velocidade da implementação paralela e a precisão da classificação. Para a realização dos experimentos, adotaremos a técnica convencional de validação cruzada, que consiste em particionar o conjunto de dados em conjuntos disjuntos e utilizar cada partição como conjunto de validação uma vez.

\section{Organização do Texto}\label{sec:LABEL_CHP_1_SEC_C}
O restante deste texto está organizado da seguinte forma: 
\par
No Capítulo \ref{chp:LABEL_CHP_2}, descrevemos a evolução da teoria de máquinas de vetores suporte, começando com a classificação de exemplos com dois parâmetros linearmente separáveis, até as perguntas mais complexas: por que é preciso escolher a maior margem possível? como é possível classificar conjuntos que não são linearmente separáveis? como lidar com exemplos imperfeitos e ruídos? Apresentamos algumas implementações de MVS e explicamos porque escolhemos o algoritmo Kernel-Adatron.

No Capítulo \ref{chp:LABEL_CHP_3}, descrevemos as características principais da programação paralela em GPU, a vantagem de se usar a GPU em detrimento da CPU, como ela funciona, para depois descrever como usar esses recursos usando a plataforma CUDA.

No Capítulo \ref{chp:LABEL_CHP_4}, descrevemos como implementamos o Kernel-Adatron. Começamos explicando a estrutura do programa, para em seguida descrever a versão sequencial e depois a versão paralela.

No Capítulo \ref{chp:LABEL_CHP_5}, apresentamos os conjuntos de dados utilizados, o hardware utilizado e quais as métricas usadas para análise. Em seguida apresentamos os resultados dos experimentos.

Por fim, no Capítulo \ref{chp:LABEL_CHP_6}, apresentamos as conclusões deste trabalho e que modificações podem melhorar o desempenho do programa.